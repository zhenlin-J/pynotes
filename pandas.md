# [Kaggle: Your Home for Data Science](https://www.kaggle.com/)
# [pandasä¸­æ–‡æ–‡æ¡£](https://www.pypandas.cn/docs/) <br>

### ä»€ä¹ˆæ˜¯pandas <br>
Pandasæ˜¯ä¸€ä¸ªå¼ºå¤§çš„åˆ†æç»“æ„åŒ–æ•°æ®çš„å·¥å…·é›†ï¼›å®ƒçš„ä½¿ç”¨åŸºç¡€æ˜¯Numpyï¼ˆæä¾›é«˜æ€§èƒ½çš„çŸ©é˜µè¿ç®—ï¼‰ï¼›ç”¨äºæ•°æ®æŒ–æ˜å’Œæ•°æ®åˆ†æï¼ŒåŒæ—¶ä¹Ÿæä¾›æ•°æ®æ¸…æ´—åŠŸèƒ½ã€‚ <br>
  - DataFrame: DataFrameæ˜¯Pandasä¸­çš„ä¸€ä¸ªè¡¨æ ¼å‹çš„æ•°æ®ç»“æ„ï¼ŒåŒ…å«æœ‰ä¸€ç»„æœ‰åºçš„åˆ—ï¼Œæ¯åˆ—å¯ä»¥æ˜¯ä¸åŒçš„å€¼ç±»å‹(æ•°å€¼ã€å­—ç¬¦ä¸²ã€å¸ƒå°”å‹ç­‰)ï¼ŒDataFrameæ—¢æœ‰è¡Œç´¢å¼•ä¹Ÿæœ‰åˆ—ç´¢å¼•ï¼Œå¯ä»¥è¢«çœ‹åšæ˜¯ç”±Seriesç»„æˆçš„å­—å…¸ã€‚ <br>
  - Series: æ˜¯ä¸€ç§ç±»ä¼¼äºä¸€ç»´æ•°ç»„çš„å¯¹è±¡ï¼Œæ˜¯ç”±ä¸€ç»„æ•°æ®(å„ç§NumPyæ•°æ®ç±»å‹)ä»¥åŠä¸€ç»„ä¸ä¹‹ç›¸å…³çš„æ•°æ®æ ‡ç­¾(å³ç´¢å¼•)ç»„æˆã€‚ä»…ç”±ä¸€ç»„æ•°æ®ä¹Ÿå¯äº§ç”Ÿç®€å•çš„Serieså¯¹è±¡ã€‚ <br>

### Seriesçš„åˆ›å»º <br>
```python
import pandas as pd

a = pd.Series([18,22,30]) # æœ€ç®€å•çš„åˆ›å»ºï¼Œé»˜è®¤ç´¢å¼•
print(a,type(a)) # dtype: int64 <class 'pandas.core.series.Series'>
# è¿™é‡Œçš„aä¸numpyä¸­ä¸€æ ·å¯ä»¥ä½¿ç”¨.astype() .detypeæ–¹æ³•

t1 = pd.Series([1,2,3,4],index=list('abcd'))
print(t1,type(t1))

dict = {
    'name':'kin',
    'age':18,
    'weight':60
}
t2 = pd.Series(dict)
print(t2,type(t2)) # dtype: object <class 'pandas.core.series.Series'>
```
Serieså¯¹è±¡æœ¬è´¨ä¸Šç”±ä¸¤ä¸ªæ•°ç»„æ„æˆï¼Œä¸€ä¸ªæ•°ç»„æ„æˆå¯¹è±¡çš„é”®(indexï¼Œç´¢å¼•)ï¼Œä¸€ä¸ªæ•°ç»„æ„æˆå¯¹è±¡çš„å€¼(value) <br>
### Seriesåˆ‡ç‰‡ä¸ç´¢å¼• <br>
```python
import pandas as pd
dict = {
    'name':'kin',
    'age':18,
    'weight':60
}
t1 = pd.Series(dict)
print(t1['name'], t1[0]) # å¯ä»¥çœ‹åˆ°é»˜è®¤æœ‰ä¸€ä¸ªåˆ›å»ºé¡ºåºç´¢å¼•
print(t1[:2], t1[2:]) # é€‰ä¸­è¿ç»­å¤šä¸ªæ•°æ®
print(t1[[0, 2]]) # é€‰ä¸­ä¸è¿ç»­çš„å¤šä¸ªæ•°æ®
# print(t2[t2>10]) # ä¹Ÿå¯ä»¥boolç´¢å¼• è¿™é‡Œå°±å†™ä¸ªä¼ªä»£ç æ¼”ç¤ºä¸€ä¸‹

print(t1.index,type(t1.index))
print(t1.values,type(t1.values))
```
### DataFrameçš„å±æ€§ <br>
```python
import pandas as pd

t1 = pd.read_csv('./demo2.csv')
t2 = pd.DataFrame(t1)
print(t2.index)
print(t2.columns)
print(t2.shape)
print(t2.dtypes)
print(t2.ndim)
print(t2.head())
print(t2.tail())
print(t2.info())
print(t2.describe())

'''.sort_values() æŒ‰å€¼æ’åº'''
t3 = t2.sort_values('ziwai',ascending=False)
print(t3)
```
è¡Œç´¢å¼•ï¼šæ¨ªå‘ç´¢å¼•ï¼Œå«indexï¼Œaxis=0 <br>
åˆ—ç´¢å¼•ï¼šçºµå‘ç´¢å¼•ï¼Œå«columnï¼Œaxis=1 <br>
DataFrameçš„å±æ€§çš„åŸºç¡€å±æ€§ï¼š <br>
  - df.shape  è¡Œæ•°åˆ—æ•° <br>
  - df.dtypes  åˆ—æ•°æ®ç´¢å¼• <br>
  - df.ndim  æ•°æ®ç»´åº¦ <br>
  - df.index  è¡Œç´¢å¼• <br>
  - df.columns  åˆ—ç´¢å¼• <br>
  - de.values  å¯¹è±¡å€¼ äºŒç»´çŸ©é˜µ <br>

DataFrameæ•´ä½“æƒ…å†µæŸ¥è¯¢ï¼š
  - df.head()  æ˜¾ç¤ºå¤´éƒ¨å‡ è¡Œ é»˜è®¤5è¡Œ <br>
  - df.tail()  æ˜¾ç¤ºæœ«å°¾å‡ è¡Œ é»˜è®¤5è¡Œ <br>
  - df.info()  ç›¸å…³ä¿¡æ¯æ¦‚è¿°ï¼šè¡Œæ•° åˆ—æ•° åˆ—ç´¢å¼• åˆ—éç©ºå€¼ä¸ªæ•° åˆ—ç±»å‹ å†…å­˜å ç”¨ <br>
  - df.describe()  å¿«é€Ÿç»¼åˆç»Ÿè®¡ç»“æœï¼šè®¡æ•° å‡å€¼ æ ‡å‡†å·® æœ€å°å€¼ å››åˆ†ä½æ•°  æœ€å¤§å€¼<br>

### DataFrameåˆ‡ç‰‡ <br>
```python
import pandas as pd
import numpy as np

t1 = pd.read_csv('./demo2.csv')
t2 = pd.DataFrame(t1)
print(t2[:7]) # å¯¹è¡Œè¿›è¡Œæ“ä½œ åˆ‡è¿ç»­çš„è¡Œ
print(t2['ziwai']) # å¯¹åˆ—è¿›è¡Œæ“ä½œ åˆ‡æŒ‡å®šçš„åˆ—

####################################################
# pandasåˆ©ç”¨æ ‡ç­¾å’Œä½ç½®ç´¢å¼•æ•°æ®
print(t2.loc[0,'ziwai'],type(t2.loc[0,'ziwai']))
print(t2.loc[[0,2],['ziwai','anqi']])
print(t2.loc[:1,]) # ğŸ˜¥ğŸ˜¥ğŸ˜¥ åªæœ‰è¿™é‡Œçš„.loc[]æ–¹æ³•é‡Œé¢çš„ : æ˜¯é—­åˆå–å€¼çš„ ä¼šå–åˆ°1
print(t2.iloc[:1,])
print(t2.iloc[:,[5]]) # æŒ‰ä½ç½®å–
t2.iloc[0,0] = np.nan # dateframeä¼šè‡ªåŠ¨æŠŠæ•°å€¼è½¬æ¢ä¸ºfloat æ‰€ä»¥è¿™é‡Œæ²¡æœ‰æŠ¥é”™
```
### DataFrameçš„å¸¸ç”¨ç»Ÿè®¡æ–¹æ³• <br>
```python
import pandas as pd
import numpy as np

t1 = pd.read_csv('./demo2.csv')
print(t1.head(26))

print(t1['chanlv'].mean()) # è·å–æŸä¸€åˆ—çš„å¹³å‡å€¼
print(len(set(t1['chanlv'].tolist()))) # ç»Ÿè®¡æŸä¸€åˆ—å»é‡åçš„å…ƒç´ ä¸ªæ•°
print(t1['chanlv'].unique()) # è·å–æŸä¸€åˆ—å»é‡åçš„å…ƒç´ 

# t2 = [i for j in t1 for i in j] # = å³è¾¹æ˜¯ä»å·¦å¾€å³æ‰§è¡Œ è¿™ä¸ªæ˜¯å¸¸è§çš„åˆ—è¡¨åµŒå¥—åˆ—è¡¨å±•å¼€çš„åŠæ³• ä½†æ˜¯è¿™é‡Œä¸èƒ½å¯¹çŸ©é˜µç”¨

t2 = np.array(t1).flatten() # å¯¹çŸ©é˜µè¿›è¡Œæ“ä½œ ç›´æ¥ç”¨numpyè‡ªå¸¦çš„æ‰å¹³åŠŸèƒ½ğŸ˜¥
t3 = len(set(t2))
print(t3) # æ•´ä¸ªçŸ©é˜µå»é‡åçš„å…ƒç´ ä¸ªæ•°
```
### å­—ç¬¦ä¸²ç¦»æ•£åŒ–æ¡ˆä¾‹ <br>
[ç”µå½±ç§ç±»çš„åˆ†ç±»ç»Ÿè®¡è¯¾ç¨‹æ¼”ç¤º](https://www.bilibili.com/video/av49778784/?p=486) <br>
æ€è·¯ï¼š <br>
`temp_genre_list = df['genre'].str.split(',').tolist()` -->å°†genreè¿™ä¸€åˆ—çš„æ•°æ®å–å‡º å­—ç¬¦ä¸²çš„æ–¹å¼ ä»¥â€œï¼Œâ€åˆ†å‰² ç„¶åè½¬åŒ–ä¸ºå¤§åˆ—è¡¨åµŒå¥—å°åˆ—è¡¨ <br>
`genre_list = []`  --> å®šä¹‰ä¸€ä¸ªç©ºåˆ—è¡¨ç”¨æ¥å­˜æ”¾ä¸‹é¢çš„è¡¨å¤´ <br>
```
for i in temp_genre_list:
	genre_list.extend(i)  # è¿™é‡Œçš„iå°±æ˜¯ä¸€ä¸ªä¸ªåˆ†å‰²åçš„ç”µå½±ç§ç±»å
genre_list = set(genre_list) # åˆ—è¡¨å»é‡
```
`zeros_genre = pd.DataFrame(np.zeros(shape=(de.shape[0],len(genre_list)),dtype=int),columns=genre_list)` --> æ„é€ ä¸€ä¸ªå…¨é›¶çŸ©é˜µï¼Œå¹¶è®¾ç½®ç”µå½±ç§ç±»ä¸ºè¡¨å¤´ <br>
```
for i in range(de.shape[0]):
	genres = df['genres'][i] # è¿™é‡Œçš„iæ˜¯éå†å¤§åˆ—è¡¨åå¾—åˆ°çš„å°åˆ—è¡¨
	zeros_genre.loc[i,genres.split(',')] =1 # è¿™é‡Œç”¨æ ‡ç­¾åæ¥å®šä½
```
`genre_count = zeros_genre.sum(axis=0)` --> å°†ç»Ÿè®¡åˆ—è¡¨æŒ‰è¡Œsumç»Ÿè®¡ <br>
### æ•°æ®çš„è¡Œåˆå¹¶ join <br>
åœ¨å­¦ä¹ çˆ¬è™«çš„æ—¶å€™ï¼Œæ›¾ç»ä½¿ç”¨è¿‡ `"".join()`æ–¹æ³•å°†æ•£ä¹±çš„å­—ç¬¦ä¸²ç»„åˆæˆä¸€ä¸ªå­—ç¬¦ä¸²ğŸ˜€ <br>
`.join()` é»˜è®¤å°†è¡Œç´¢å¼•ç›¸åŒçš„æ•°æ®åˆå¹¶åˆ°ä¸€èµ· <br>
```ä¼ªä»£ç 
   0  1             X  Y            0  1  X  Y
A  1  2          A  7  8         A  1  2  7  8
B  3  4   join   B  9  0   ->    B  3  4  9  0
C  5  6                          C  5  6  NaN NaN
```
```python
import pandas as pd
import numpy as np

t1 = pd.DataFrame(np.ones((2,4)),columns=list('abcd'))
t2 = pd.DataFrame(np.zeros((3,3)),columns=list('xyz'))
# print(t1.join(t2))
print(t2.join(t1))
```
ç»æµ‹è¯•å‘ç°åˆ—åå¦‚æœé‡å ï¼Œä¼šæŠ¥é”™ğŸ˜„ <br>
`ValueError: columns overlap but no suffix specified: Index(['a', 'b', 'c'], dtype='object')` <br>
### æ•°æ®çš„åˆå¹¶ merge <br>
```python
import pandas as pd
import numpy as np

t1 = pd.DataFrame(np.ones((4,4)),columns=list('abcd'))
t2 = pd.DataFrame(np.zeros((3,3)),columns=list('xyz'))
t3 = pd.DataFrame(np.arange(9).reshape((3,3)),columns=list('afx'))
print(t1)
print(t2)
print(t3)
print(t1.merge(t3,on='a'))
t1.loc[2,'a'] = 6
t1.loc[0,'a'] = 9
t1.loc[3,'a'] = 0
t3.loc[1,'a'] = 1
t3.loc[0,'a'] = 0
print(t1)
print(t3)
print(t1.merge(t3,on='a'))
# é»˜è®¤çš„mergeæ–¹å¼æ˜¯inner äº¤é›† æµ‹è¯•äº†å‡ æ³¢å‘ç°äº†è§„å¾‹ è¿™ä¸ªé»˜è®¤çš„åˆå¹¶å¾ˆè¯¡å¼‚ å½“t1ä¸t3çš„'a'æ ‡ç­¾ä¸­å‡ºç°ç›¸åŒçš„å…ƒç´  å‡ºç°å‡ æ¬¡ å°±ä¼šå°†æ­¤è¡Œæ•°æ®åˆå¹¶ å°†ä¸ç›¸åŒçš„å…ƒç´ çš„è¡ŒæŠ›å¼ƒ è¿™ä¸ªåˆ¤å®šå¾ˆè¿· é€ä¸ªå…ƒç´ åˆ¤å®š è€Œä¸”æ„Ÿè§‰è¿˜æœ‰ä¸ªé‡æ–°æ’åºçš„æ•ˆæœä½†æ˜¯æ’åºè§„åˆ™ä¸æ˜

# å½“æŒ‡å®šå…¶ä»–çš„æ–¹å¼æ—¶
print(t1.merge(t3, on='a',how='outer'))
# æŒ‡å®šouteræ—¶ å¹¶é›† ä¸ç›¸åŒçš„å…ƒç´ ä¸ä¼šè¢«æŠ›å¼ƒ è¿˜æ˜¯ä¼šè¿åœ¨ä¸€èµ· ç¼ºå¤±çš„éƒ¨åˆ†ä»¥NaNè¡¥é½
print(t1.merge(t3, on='a',how='left'))
# æŒ‡å®šleftæ—¶ä¼šä»¥å·¦è¾¹çš„ä¸ºå‡† ä¸ä¼šæŠ›å¼ƒå·¦è¾¹çš„ä»»ä½•ä¸€è¡Œ ç¼ºå¤±çš„éƒ¨åˆ†ä»¥NaNè¡¥é½
print(t1.merge(t3, on='a',how='right'))
# æŒ‡å®šrightæ—¶ä¼šä»¥å³è¾¹çš„ä¸ºå‡† ä¸ä¼šæŠ›å¼ƒå³è¾¹çš„ä»»ä½•ä¸€è¡Œ ç¼ºå¤±çš„éƒ¨åˆ†ä»¥NaNè¡¥é½

# å½“æ ‡ç­¾æ²¡æœ‰ç›¸åŒçš„æ—¶å€™ å¯ä»¥ç”¨ left_on right_on æ¥åˆ†åˆ«æŒ‡å®šæ ‡å‡† è¿™ä¸ªéƒ¨åˆ†å¾ˆæ‚ ä¸æ•°æ®åº“My SQLæ“ä½œå¾ˆåƒ
```
### æ•°æ®çš„åˆ†ç»„èšåˆ <br>
.groupby()å‡½æ•°demo <br>
```python
import pandas as pd
import numpy as np

t1 = pd.read_csv('./demo3.csv')

# æŒ‰å¤§æ ‡ç­¾countryæ¥åˆ†ç»„
# t1_country = t1.groupby(by='country') # æŒ‰ç…§å›½å®¶åˆ†ç»„
# print(t1_country,type(t1_country)) # åˆ†ç»„åçš„æ•°æ®å¯ä»¥éå†æˆ–è€…èšåˆ
# for i in t1_country:
#     print(i) # (,) è¿”å›å…ƒç»„ç±»å‹
#
# print(t1_country['country'].count()) # éšä¾¿æŠ½å–ä¸€åˆ—æ²¡æœ‰ç¼ºå¤±çš„æ•°æ®
# t2 = t1_country['country'].count()
# print(t2['china']) # å•ç‹¬æŠ½å–å‡ºä¸€åˆ—åæ‰èƒ½å–è¡Œç´¢å¼•


# ç»Ÿè®¡countryä¸‹é¢ä¸­å›½ç»„é‡Œé¢å„ä¸ªprovinceçš„ä¿¡æ¯
print(t1)
china_date = t1[t1["country"] == 'china'] # åˆ¤æ–­ç”¨== ä¸è¦ç”¨èµ‹å€¼=
print(china_date)
grouped = china_date.groupby(by='province').count()['store number']
grouped = china_date.groupby(by='province').sum()['store number']
grouped = china_date.groupby(by='province').mean()['store number']
grouped = china_date.groupby(by='province').median()['store number']
grouped = china_date.groupby(by='province').std()['store number']
grouped = china_date.groupby(by='province').var()['store number']
grouped = china_date.groupby(by='province').min()['store number']
print(grouped)
print('@'*80)

# ä¹Ÿå¯ä»¥åœ¨åˆ†ç»„çš„æ—¶å€™ä¼ å…¥ä¸¤ä¸ªå‚æ•°
grouped = t1.groupby(by=[t1['country'],t1['province']]).count()['store number'] # è¿™é‡Œä¸€åˆ—æ•°æ®æœ‰ä¸¤ä¸ªç´¢å¼• å¤åˆç´¢å¼•
grouped = t1.groupby(by=[t1['country'],t1['province']]).count()[['store number']] # è¯­æ³•æ˜¯è¦å–å¤šä¸ª ä½†æ˜¯ä¼ å‚æ•°æ˜¯åªä¼ å…¥ä¸€ä¸ª è¿™æ ·è¿”å›å€¼å°±æ˜¯dateframeç±»å‹
print(grouped,type(grouped))
```
### ç´¢å¼•å’Œç¬¦åˆç´¢å¼• <br>
è®°ä½è¿™é‡Œçš„ç´¢å¼•æ˜¯è¡Œç´¢å¼•
  - df.index  è·å–index <br>
  - df.index=['x','y'...]  æŒ‡å®šindex ä¸ªæ•°è¦ä¸è¡Œæ•°å¯¹åº” <br>
  - df.reindex([..])  ä»¥æ–°çš„indexæ¥åœ¨è¡Œä¸­å¯»æ‰¾ï¼Œæœ‰çš„å°±ä¸å˜ï¼Œæ²¡æœ‰çš„å–NaN<br>
  - df.set_index('column', drop=False)  æŒ‡å®šæŸä¸€åˆ—ä½œä¸ºç´¢å¼• <br>
  - de.set_index('column').index.unique()  æŒ‡å®šçš„åˆ—çš„å…ƒç´ å¯èƒ½æœ‰é‡å¤çš„ï¼Œè¿™é‡Œå…ˆæ‰¾åˆ°æŒ‡å®šçš„ç´¢å¼•çš„ç´¢å¼•ï¼Œç„¶åå»é‡ <br>

```python
import pandas as pd
import numpy as np

t1 = pd.DataFrame(np.arange(12).reshape((3,4)),index=list('abc'))
# t1.index = ['x','y'] # å°‘ä¸€ä¸ªä¼šæŠ¥é”™
t1.reindex(['i','d']) # å—¯=ã€‚=ä¸çŸ¥é“ä¸ºå•¥è¿™ä¸ªæ“ä½œæ²¡æœ‰ç”¨ å“¦ è¿™ä¸ªæ“ä½œæ²¡æœ‰èµ‹å€¼ä¸ä¼šè¿”å›å€¼
print(t1.reindex(['i','d']))
print(t1.set_index(0,drop=False)) # è¿™é‡Œçš„æ–°çš„ç´¢å¼•åå«0 dropé»˜è®¤ä¸ºTrue ä¼šåˆ æ‰è½¬ä¸ºindexçš„åˆ—
print(t1[0].unique())
################################################################
t2 = t1.set_index(0,drop=False)
print(t2.index.unique()) # è¿”å›çš„æ˜¯ç´¢å¼•çš„å»é‡å€¼
# è¿™é‡Œçš„indexä¸æ­¢uniqueå»é‡è¿™ä¸ªæ–¹æ³• è¿˜æœ‰é•¿åº¦len åˆ—è¡¨listç­‰ç­‰ æ˜¯ä¸ªå¯ç¼–è¾‘å¯¹è±¡
################################################################
t3 = t1.set_index([3,1],drop=False) # ä¸€æ¬¡æ‰”ä¸¤ç»„åˆ—ä½œä¸ºç´¢å¼•
print(t3)
print(t3.index)
################################################################
t4 = t1.set_index([0,1,2])
print(t4) # å°±ç®—åªå‰©ä¸‹ä¸€åˆ—æ•°æ® è¿™é‡Œè¿˜æ˜¯dateframeå±æ€§
t5 = t4[3] # ä»dateframeä¸­å–å‡ºä¸€åˆ— å°±ç®—åªæœ‰1åˆ— å–å‡ºåå°±ä¼šå˜æˆseries è€Œä¸”ä¿ç•™åŸæœ‰çš„å¤šä¸ªæ ‡ç­¾ç»„ ä½†æ˜¯åˆ—åå°±ä¼šä¸¢å¤± å°±ä¸€åˆ—è¦ä»€ä¹ˆåˆ—å
print(t5)
# è¿™é‡Œçš„serieså¯¹åº”3ä¸ªæ ‡ç­¾ç»„ å¯¹äºå®é™…æƒ…å†µè€Œè¨€ ç´¢å¼•ä¸ç´¢å¼•ä¹‹é—´æ˜¯åˆ†å±‚çš„ å¤§çš„ç´¢å¼•å¯èƒ½å¯¹åº”å¾ˆå¤šä¸ªå…ƒç´  å°±åƒä¹‹å‰çš„ä¸­å›½ç´¢å¼•ä¸‹é¢è¿˜å¯ä»¥åˆ†ä¸ºçœä»½ç´¢å¼• å½“å¤§ç´¢å¼•åœ¨å·¦è¾¹æ—¶å¯ä»¥æ–¹ä¾¿çš„ç›´æ¥ä½¿ç”¨å¤§ç´¢å¼•è·å–å¤šä¸ªå€¼
# .swaplevel() äº¤æ¢ç´¢å¼•å±‚çº§çš„å‡½æ•°
print(t5.swaplevel(0,1)) # è¾“å…¥ç´¢å¼•åçš„å‚æ•°å³å¯å°†ä¸¤ä¸ªç´¢å¼•è°ƒæ¢ä½ç½®
#################################################################
# å¯¹äºdateframe ç›´æ¥ä½¿ç”¨t4[".."]æ—¶é»˜è®¤ä½¿ç”¨åˆ—ç´¢å¼• è¦ä½¿ç”¨è¡Œç´¢å¼•å°±éœ€è¦ç”¨.loc()å‡½æ•°
print(t4)
print(t4.loc[0].loc[1].loc[2])
print(t4.loc[0,1,2]) # è¿™æ ·å¯ä»¥ç®€åŒ–è¯­æ³•
```
æœ‰å…³DateFrameå’ŒSeriesçš„ç´¢å¼•çŸ¥è¯†ç‚¹å¾ˆé‡è¦ï¼Œæ˜¯æŸ¥è¯¢ç­›é€‰æ•°æ®çš„åŸºç¡€ğŸ˜€Î¿(=â€¢Ï‰ï¼œ=)ÏâŒ’â˜† <br>
```
t1 = pd.read_csv('./demo3.csv')
# æ‰¾å‡ºåº—é“ºæ€»æ•°æ’åå‰2çš„å›½å®¶
t2 = t1.groupby(by='country').count()['store number'].sort_values(ascending=False)[:2] # å–å‰é¢ä¸¤è¡Œæ•°æ®
```
è¿™æ®µä»£ç çœ‹å¾—æ‡‚å—ï¼Ÿ <br>
### ä¼˜åŒ–ä»£ç  <br>
```python
import pandas as pd
import numpy as np
t0 = pd.read_csv('./books.csv')
t1 = t0.iloc[:,:16] # å»æ‰é‚£ä¸ªå¾ˆsbçš„æœ€åä¸€åˆ—

# è·å–æ¯ä¸€å¹´å‡ºç‰ˆé¢å¥½ä¹¦æ•°é‡
t2 = t1[t1['original_publication_year'] != np.nan] # å»æ‰original_publication_yearæ ‡ç­¾ä¸­ç¼ºå¤±çš„éƒ¨åˆ†
t3= t2.groupby(by='original_publication_year').count()['title']
# print(t3) # è‡³æ­¤å°±è·å¾—äº†æ¯ä¸€å¹´å‡ºç‰ˆçš„æ•°çš„åˆ†å¸ƒ

# è·å–ä¸åŒå¹´ä»½ä¹¦çš„å¹³å‡è¯„åˆ†
t4 = t2['average_rating'].groupby(by=t2['original_publication_year']).mean()
# print(t4)

#######################################################
a0 = pd.read_csv('./911.csv')
# print(a0['title'])
print(a0.info()) # æˆ‘ä»–å¦ˆçœŸæ˜¯æ—¥äº†ç‹—äº†=ã€‚=è¿™é‡Œçš„infoè¦åŠ ()
a1 = a0['title'].str.split(':').tolist()
# a2 = []
# for i in a1:
#     a2.append(i[0])
a2 = list(set([i[0] for i in a1])) # è£…é€¼æµå†™æ³•
print(a2) # å°±ä¸‰ä¸ªåˆ†ç±» å­—ç¬¦ä¸²åˆ†ç¦»åå°±å¯ä»¥æ„å»ºå…¨é›¶çŸ©é˜µæ¥ç»Ÿè®¡äº†

#######################################################
zeros = pd.DataFrame(np.zeros(shape=(a0.shape[0],len(a2))),columns=a2)
# è¿™é‡Œçš„è¡Œæœ‰43ä¸‡ä¹‹å¤š å¦‚æœéå†è¡Œ ä¼šéå¸¸çš„æ…¢ å› æ­¤åº”è¯¥è€ƒè™‘éå†åˆ— ç›¸æ¯”ä¹‹ä¸‹åˆ—åªæœ‰3ä¸ª
for i in a2: # ç›¸å½“äºä¼˜åŒ–ç®—æ³•
    zeros[i][a0['title'].str.contains(i)] = 1
    # å¸ƒå°”ç´¢å¼•
print(zeros)
# for i in range(a0.shape[0]): # è¿™ä¸ªè€ç®—æ³•å¤ªæ…¢äº† å¯è§ä¼˜åŒ–ç®—æ³•çš„é‡è¦æ€§
#     zeros.loc[i,a1[i][0]] = 1
# print(zeros)
print(zeros.sum(axis=0)) # è‡³æ­¤ä¸åŒç±»å‹çš„ç´§æ€¥æƒ…å†µçš„æ¬¡æ•°å°±ç»Ÿè®¡å‡ºæ¥äº†(à¸‡ â€¢_â€¢)à¸‡

########################################################
b0 = pd.read_csv('./911.csv')
b1 = b0['title'].str.split(':').tolist()
b2 = [[i[0] for i in b1]]
# print(b2) # æ­£ç¡® å¼€å§‹åˆ›å»ºä¸€ä¸ªåˆ— ç„¶åå°†åˆ—å¹¶å…¥åŸæœ‰çš„dateframe
b3 = pd.DataFrame(np.array(b2).transpose())
print(b3) # å‘ç°ç›´æ¥èµ‹å€¼å¾—åˆ°çš„æ˜¯ä¸€ä¸ªè¡Œ éœ€è¦resape æˆ–è€…è°ƒç”¨çŸ©é˜µçš„è½¬ç½®å‡½æ•°
b0['type'] = b3 # å°†åˆ—æ·»åŠ è¿›å»
print(b0.groupby(by='type').count()['title'])
# è¾¾åˆ°äº†åŒæ ·çš„æ•ˆæœï¼å¯å°†è¿™ç§æ€è·¯å¾ˆä¸é”™ï¼å¯ä»¥ä½œä¸ºä¸€ä¸ªå›ºå®šçš„å¢åŠ æ–°çš„åˆ—ï¼Œç„¶åä½¿ç”¨groupbyæ¥è°ƒç”¨countç­‰æ–¹æ³•
# è¿™é‡Œåšçš„äº‹å…¶å®ä¸å¤š å°±æ˜¯å°†åˆ—è¡¨ä¸­çš„ä¸åŒå…ƒç´ åšäº†countç»Ÿè®¡ æ–¹æ³•æ˜¯åˆ©ç”¨dateframeæ¡†æ¶é‡Œé¢é›†æˆçš„å‡½æ•°

# ä¸‹é¢è¿˜å¯ä»¥å¯¹æ—¶é—´æˆ³æ ‡ç­¾ä¸‹çš„åˆ—è¿›è¡Œç±»ä¼¼çš„æ“ä½œ å¯ä»¥æå–å…¶ä¸­çš„æœˆä»½ä¿¡æ¯ ç„¶åå’Œä¸Šé¢ä¸€æ · å‰¥ç¦» æ‰“ç»„ åˆå¹¶ åˆ†ç»„ è°ƒç”¨countå‡½æ•°
# ä½†æ˜¯pandasé‡Œé¢æœ‰ä¸“é—¨å¯¹æ—¶é—´åºåˆ—çš„è§£å†³æ–¹æ¡ˆ è¿™æ ·ä¼šæ›´åŠ çš„æ–¹ä¾¿
```
### pandasçš„æ—¶é—´åºåˆ— <br>
![pandasæ—¶é—´åºåˆ—çš„é¢‘ç‡.png](./images/pandasæ—¶é—´åºåˆ—çš„é¢‘ç‡.png)
#### pandasé‡é‡‡æ · <br>
.resample()  é‡é‡‡æ ·æŒ‡çš„æ˜¯å°†æ—¶é—´åºåˆ—ä»ä¸€ä¸ªé¢‘ç‡è½¬åŒ–ä¸ºå¦ä¸€ä¸ªé¢‘ç‡è¿›è¡Œå¤„ç†çš„è¿‡ç¨‹ï¼Œå°†é«˜é¢‘æ•°æ®è½¬åŒ–ä¸ºä½é¢‘æ•°æ®ä¸ºé™é‡‡æ ·(æ˜¾ç„¶é™é‡‡æ ·ç”¨çš„æ›´å¤š)ï¼Œä½é¢‘è½¬é«˜é¢‘ä¸ºå‡é‡‡æ · <br>
```python
import pandas as pd
import numpy as np

'''.date_range() åˆ›å»ºä¸€æ®µæ—¶é—´èŒƒå›´'''
'''.date_range(start=None,end=None,periods=None,freq='D')'''
t1 = pd.date_range(start='20171230',end='20180501',freq='10D')
print(t1)
t2 = pd.date_range(start='20171230',periods=10,freq='M')
print(t2)

'''.to_datetime('',format='')'''
a = pd.read_csv('./911.csv')
# ä¸‹é¢å¼€å§‹é™é‡‡æ ·
a['timeStamp'] = pd.to_datetime(a['timeStamp']) # å°†å­—ç¬¦ä¸²è½¬åŒ–ä¸ºpandasçš„æ—¶é—´åºåˆ—
# ä¸Šé¢è¿™ä¸ªèµ‹å€¼åªæ˜¯å¢åŠ äº†ä¸€ä¸ªåˆ— è™½ç„¶åˆ—åæ˜¯ä¸€æ ·çš„ ä½†æ˜¯ä¸ä¼šè¦†ç›– è¿˜è¦è°ƒç”¨ç´¢å¼•çš„å‡½æ•°
# a.set_index('timeStamp',inplace=True) # åŸåœ°æ›¿æ¢ å°±æ˜¯è¦†ç›–
# è¿™é‡Œç†è§£é”™è¯¯äº† inplaceçš„æ„æ€æ˜¯ä¿®æ”¹dateframe ä½†æ˜¯ä¸åˆ›å»ºæ–°çš„å¯¹è±¡ å¯ä»¥ç†è§£ä¸ºæ²¡æœ‰è¿™ä¸€é¡¹å°±éœ€è¦å®šä¹‰ä¸€ä¸ªæ–°çš„å¯¹è±¡å»æ¥å—è¿™ä¸ªa
print('$'*80)
print(a.head(2))
# count_by_month = a.resample('M').count()['title'] # pandasçœŸå¥½ç”¨( â€¢Ì€ Ï‰ â€¢Ì )âœ§
# print(count_by_month) # è¿™æ ·å°±å¾ˆæ–¹ä¾¿çš„æŒ‰æœˆæ¥ç»Ÿè®¡äº†

#########################################################################
# è¿›ä¸€æ­¥å¢åŠ è¦æ±‚ï¼Œç°åœ¨è¦å¯¹ç»Ÿè®¡æœˆ ç»Ÿè®¡ç§ç±» æ€è·¯ä»ç„¶æ˜¯å¢åŠ ä¸€ä¸ªåˆ—
a1 = a['title'].str.split(':').tolist() # å¤§åˆ—è¡¨å¥—å°åˆ—è¡¨
a2 = [i[0] for i in a1] # éå†å–å€¼
a['type'] = pd.DataFrame(np.array(a2).transpose()) # è½¬ç½® ç„¶åå¤åˆ¶æ·»åŠ åˆ— ä¸èƒ½å…ˆä¿®æ”¹ç´¢å¼• ä¸ç„¶è¿™é‡Œçš„ç´¢å¼•æ²¡æœ‰è®¾ç½®å°±æ˜¯é»˜è®¤çš„0 1 2...
a.set_index('timeStamp',inplace=True)
count_by_month = a.resample('M').count()['title'] # pandasçœŸå¥½ç”¨( â€¢Ì€ Ï‰ â€¢Ì )âœ§
print(count_by_month)
print(a.head(2))

# for gp_type in a.groupby(by='type'): # è¿™é‡Œçš„typeåªæœ‰ä¸‰ä¸ªå»é‡å…ƒç´  æ˜¾ç„¶æ˜¯å¤–ç´¢å¼• ä¸ºäº†ä¼˜åŒ–ç®—æ³• è¿™é‡Œå°±å…ˆéå†å¤–ç´¢å¼•
#     count_by_month = gp_type.resample('M').count()['title']
# # è¿™é‡Œæœ‰äº›é—®é¢˜è¿˜ä¸å¤ªæ˜ç™½
```
pandasçš„æ—¶é—´åºåˆ—è¿˜æœ‰æ¯”è¾ƒå¸¸è§çš„å‡½æ•°`padas.PeriodIndex()`ç”¨æ¥å°†åˆ†å‰²çš„æ—¶é—´æˆ³ç»„åˆæˆæ—¶é—´æ®µ <br>
`timeStamp = pandas.PeriodIndex(year=a['year'],month=a['month'],day=['day'],hour=a['hour'],freq='H')` <br>
è¿˜æœ‰ä¸€ä¸ªå‡½æ•°ï¼Œä¸¢æ‰ç¼ºå¤±çš„å€¼`.dropna()`å¯ä»¥ç”¨æ¥ä¸¢æ‰æœ‰ç¼ºçœæ•°æ®çš„è¡Œï¼Œå½“ç„¶åˆ—ä¹Ÿå¯ä»¥ä½†æ˜¯å¾ˆå°‘ç”¨åˆ—ï¼Œä¸ä¼šå‡å°‘æ•°æ®